[{"content":"前言 市面上MQTT Sever 有很多種，例如: EMQX Mosquitto 這次我們透過docker來建立IOT傳輸用的MQTT Sever EMQX 步驟 建立一個新的folder，命名emqx 在emqx目錄底下，建立名為data資料夾，用來存放eqmx資料 在emqx目錄底下，建立docker-compose.yml docker-compose.yml 底下輸入 version: \u0026#39;3\u0026#39; services: emqx: image: emqx:5.0.20 container_name: emqx healthcheck: test: [\u0026#34;CMD\u0026#34;, \u0026#34;/opt/emqx/bin/emqx_ctl\u0026#34;, \u0026#34;status\u0026#34;] interval: 5s timeout: 25s retries: 5 ports: - 1883:1883 ## tcp - 8083:8083 ## websockeet - 8084:8084 ## websocket ssl - 8883:8883 ## ssl - 18083:18083 ## web volumes: - ./data:/opt/emqx/data 執行docker-compose up -d，即可啟動emqx 打開browser，在localhost:18083即可看到啟動好的emqx，如下圖 預設帳密為: admin/public 參考連結 EQMX ","permalink":"https://tonywu1995.github.io/devops/emqx/","summary":"前言 市面上MQTT Sever 有很多種，例如: EMQX Mosquitto 這次我們透過docker來建立IOT傳輸用的MQTT Sever EMQX 步驟 建立一個新的folder，命名emqx 在emqx目錄底下，建立名為data資料夾，用來存放eqmx資料 在emqx目錄底下，建立docker-compose.yml docker-compose.yml 底下輸入 version: \u0026#39;3\u0026#39; services: emqx: image: emqx:5.0.20 container_name: emqx healthcheck: test: [\u0026#34;CMD\u0026#34;, \u0026#34;/opt/emqx/bin/emqx_ctl\u0026#34;, \u0026#34;status\u0026#34;] interval: 5s timeout: 25s retries: 5 ports: - 1883:1883 ## tcp - 8083:8083 ## websockeet - 8084:8084 ## websocket ssl - 8883:8883 ## ssl - 18083:18083 ## web volumes: - ./data:/opt/emqx/data 執行docker-compose up -d，即可啟動emqx 打開browser，在localhost:18083即可看到啟動好的emqx，如下圖 預設帳密為: admin/public 參考連結 EQMX ","title":"MQTT Server - EMQP建立"},{"content":"前言 redis exporter是用來監控Redis一個Prometheus Client，提供相關redis的監控metrics 步驟 建立一個新的folder，命名redis 在redis目錄底下，建立docker-compose.yml docker-compose.yml 底下輸入 version: \u0026#39;3\u0026#39; services: redis: restart: always container_name: redis image: redis:6.2.7-alpine ports: - 6379:6379 redis-exporter: restart: always image: oliver006/redis_exporter:v1.45.0-alpine container_name: redis-exporter ports: - 9121:9121 command: - \u0026#39;--redis.addr=redis://redis-server:6379\u0026#39; 執行docker-compose up -d，redis服務與redis exporter即可啟動\n確認redis exporter服務，已經在執行輸入curl http://localhost:9121/metrics\nλ curl http://localhost:9121/metrics # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\u0026#34;0\u0026#34;} 0 go_gc_duration_seconds{quantile=\u0026#34;0.25\u0026#34;} 0 go_gc_duration_seconds{quantile=\u0026#34;0.5\u0026#34;} 0 go_gc_duration_seconds{quantile=\u0026#34;0.75\u0026#34;} 0 go_gc_duration_seconds{quantile=\u0026#34;1\u0026#34;} 0 go_gc_duration_seconds_sum 0 go_gc_duration_seconds_count 0 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 6 # HELP go_info Information about the Go environment. # TYPE go_info gauge go_info{version=\u0026#34;go1.19.2\u0026#34;} 1 # HELP go_memstats_alloc_bytes Number of bytes allocated and still in use. # TYPE go_memstats_alloc_bytes gauge go_memstats_alloc_bytes 284752 # HELP go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed. # TYPE go_memstats_alloc_bytes_total counter go_memstats_alloc_bytes_total 284752 # HELP go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table. # TYPE go_memstats_buck_hash_sys_bytes gauge go_memstats_buck_hash_sys_bytes 4267 ... 參考連結 Redis Redis Exporter ","permalink":"https://tonywu1995.github.io/prometheus/redis-exporter/","summary":"前言 redis exporter是用來監控Redis一個Prometheus Client，提供相關redis的監控metrics 步驟 建立一個新的folder，命名redis 在redis目錄底下，建立docker-compose.yml docker-compose.yml 底下輸入 version: \u0026#39;3\u0026#39; services: redis: restart: always container_name: redis image: redis:6.2.7-alpine ports: - 6379:6379 redis-exporter: restart: always image: oliver006/redis_exporter:v1.45.0-alpine container_name: redis-exporter ports: - 9121:9121 command: - \u0026#39;--redis.addr=redis://redis-server:6379\u0026#39; 執行docker-compose up -d，redis服務與redis exporter即可啟動\n確認redis exporter服務，已經在執行輸入curl http://localhost:9121/metrics\nλ curl http://localhost:9121/metrics # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\u0026#34;0\u0026#34;} 0 go_gc_duration_seconds{quantile=\u0026#34;0.25\u0026#34;} 0 go_gc_duration_seconds{quantile=\u0026#34;0.5\u0026#34;} 0 go_gc_duration_seconds{quantile=\u0026#34;0.75\u0026#34;} 0 go_gc_duration_seconds{quantile=\u0026#34;1\u0026#34;} 0 go_gc_duration_seconds_sum 0 go_gc_duration_seconds_count 0 # HELP go_goroutines Number of goroutines that currently exist.","title":"Redis Exporter建立"},{"content":"介紹 Redis 是一個開源的in memory key value cache,常用來降低服務內的延遲情況\nRedis 支援的data type\nStrings Lists Sets Hash Sroted sets Streams Geospatial HyperLogLog Bitmaps Bitfields 現在讓我們開始安裝Redis\n建立 Redis 建立一個新的folder，命名redis-server 在redis-server目錄底下，建立docker-compose.yml docker-compose.yml 底下輸入 version: \u0026#39;3\u0026#39; services: redis: restart: always container_name: redis image: redis:6.2.7-alpine ports: - 6379:6379 執行docker-compose up -d，redis服務即可啟動\n確認redis服務，已經在執行\nλ docker exec -it redis sh /data # redis-cli 127.0.0.1:6379\u0026gt; ping PONG 127.0.0.1:6379\u0026gt; exit /data # redis-cli ping PONG /data # 小結 redis 已經安裝完成，下一章節將會開始使用java連接redis 參考連結 Redis ","permalink":"https://tonywu1995.github.io/redis/redis/","summary":"介紹 Redis 是一個開源的in memory key value cache,常用來降低服務內的延遲情況\nRedis 支援的data type\nStrings Lists Sets Hash Sroted sets Streams Geospatial HyperLogLog Bitmaps Bitfields 現在讓我們開始安裝Redis\n建立 Redis 建立一個新的folder，命名redis-server 在redis-server目錄底下，建立docker-compose.yml docker-compose.yml 底下輸入 version: \u0026#39;3\u0026#39; services: redis: restart: always container_name: redis image: redis:6.2.7-alpine ports: - 6379:6379 執行docker-compose up -d，redis服務即可啟動\n確認redis服務，已經在執行\nλ docker exec -it redis sh /data # redis-cli 127.0.0.1:6379\u0026gt; ping PONG 127.0.0.1:6379\u0026gt; exit /data # redis-cli ping PONG /data # 小結 redis 已經安裝完成，下一章節將會開始使用java連接redis 參考連結 Redis ","title":"Redis建立"},{"content":"前言 AOP 全名為:Aspect-Oriented Programming，在Java中如何實現呢?\n透過Design Pattern 中的Proxy Pattern來實現 透過AspectJ or Spring Aop來實現 本章節主要講Proxy Pattern的實現方式\n主要內容 我們有個需求是，需要提升查詢的效能，所以我們的做法是增加Cache Version 1 第一個版本，我們先建立的代碼 建立一個service 和一個repo，從repo 拿取相對應的user public class FindUserService { private final UserRepo userRepo; public FindUserService(final UserRepo userRepo) { this.userRepo = userRepo; } public User find(String username) { return userRepo.findByUsername(username); } } @AllArgsConstructor @NoArgsConstructor @Data @Builder public class User { String username; String password; } public interface UserRepo { User findByUsername(String username); } public class UserAdapter implements UserRepo { private final Map\u0026lt;String, User\u0026gt; userMap; private final ReentrantReadWriteLock lock; public UserAdapter(final Map\u0026lt;String, User\u0026gt; userMap) { this.userMap = userMap; this.lock = new ReentrantReadWriteLock(); } @Override public User findByUsername(final String username) { try { lock.readLock().lock(); return userMap.get(username); } catch (Exception e) { //tbd error throw new RuntimeException(e); } finally { lock.readLock().unlock(); } } } Version 2 接者我們對UserAdapter進行refactor成proxy pattern\n建立UserProxyAdapter，且將Lock行為的程式都抽到這裡\npublic class UserProxyAdapter implements UserRepo { private final UserRepo userRepo; private final ReentrantReadWriteLock lock; //注入UserAdapter public UserProxyAdapter(UserRepo userRepo) { this.lock = new ReentrantReadWriteLock(); this.userRepo = userRepo; } @Override public User findByUsername(final String username) { try { lock.readLock().lock(); return userRepo.findByUsername(username); } catch (Exception e) { //tbd error throw new RuntimeException(e); } finally { lock.readLock().unlock(); } } } 而原始的UserRepo，改為 public class UserAdapter implements UserRepo { private final Map\u0026lt;String, User\u0026gt; userMap; public UserAdapter(final Map\u0026lt;String, User\u0026gt; userMap) { this.userMap = userMap; } @Override public User findByUsername(final String username) { return userMap.get(username); } } 小結 這種方式的改動，讓我們的將關注點分離並且讓Code更好測試與達到SRP的目標 參考連結 Wiki Proxy Pattern ","permalink":"https://tonywu1995.github.io/java/aop-1/","summary":"前言 AOP 全名為:Aspect-Oriented Programming，在Java中如何實現呢?\n透過Design Pattern 中的Proxy Pattern來實現 透過AspectJ or Spring Aop來實現 本章節主要講Proxy Pattern的實現方式\n主要內容 我們有個需求是，需要提升查詢的效能，所以我們的做法是增加Cache Version 1 第一個版本，我們先建立的代碼 建立一個service 和一個repo，從repo 拿取相對應的user public class FindUserService { private final UserRepo userRepo; public FindUserService(final UserRepo userRepo) { this.userRepo = userRepo; } public User find(String username) { return userRepo.findByUsername(username); } } @AllArgsConstructor @NoArgsConstructor @Data @Builder public class User { String username; String password; } public interface UserRepo { User findByUsername(String username); } public class UserAdapter implements UserRepo { private final Map\u0026lt;String, User\u0026gt; userMap; private final ReentrantReadWriteLock lock; public UserAdapter(final Map\u0026lt;String, User\u0026gt; userMap) { this.","title":"Aop(上)"},{"content":"前言 使用到 SSH Tunnel 情境\n這裡有一台Server，上面架設一個Postgres，因為公司資安的關係，並不對外開啟port:5432 我們目前在Local開發一個服務，需要連線到Server上的Postgres，不太可能每次改完程式，部署上去測試，這樣來回時間會拉很長\n主要內容 ssh -L [local_ip]:[local_port]:[host_ip]:[host_port] username@host local_ip :本地ip位置，預設綁定本機 local_port:本地開啟port host_ip:遠端Server ip host_port:遠端要轉發port L: 建立Tunnel Example ssh -L 5432:localhost:5432 tony@123.456.789.10 參考連結 SSH Tunnel 突破防火牆限制 ","permalink":"https://tonywu1995.github.io/devops/ssh_tunnel/","summary":"前言 使用到 SSH Tunnel 情境\n這裡有一台Server，上面架設一個Postgres，因為公司資安的關係，並不對外開啟port:5432 我們目前在Local開發一個服務，需要連線到Server上的Postgres，不太可能每次改完程式，部署上去測試，這樣來回時間會拉很長\n主要內容 ssh -L [local_ip]:[local_port]:[host_ip]:[host_port] username@host local_ip :本地ip位置，預設綁定本機 local_port:本地開啟port host_ip:遠端Server ip host_port:遠端要轉發port L: 建立Tunnel Example ssh -L 5432:localhost:5432 tony@123.456.789.10 參考連結 SSH Tunnel 突破防火牆限制 ","title":"SSH_Tunnel"},{"content":"前言 node exporter是用來監控Linux vm的一個Prometheus Client 提供: CPU 使用率、硬碟使用率\u0026hellip; metrics 步驟 安裝Node Exporter在Ubuntu20.04 #!/bin/bash version=\u0026#34;${VERSION:-1.2.2}\u0026#34; arch=\u0026#34;${ARCH:-linux-amd64}\u0026#34; bin_dir=\u0026#34;${BIN_DIR:-/usr/local/bin}\u0026#34; wget \u0026#34;https://github.com/prometheus/node_exporter/releases/download/v$version/node_exporter-$version.$arch.tar.gz\u0026#34; \\ -O /tmp/node_exporter.tar.gz mkdir -p /tmp/node_exporter cd /tmp || { echo \u0026#34;ERROR! No /tmp found..\u0026#34;; exit 1; } tar xfz /tmp/node_exporter.tar.gz -C /tmp/node_exporter || { echo \u0026#34;ERROR! Extracting the node_exporter tar\u0026#34;; exit 1; } sudo cp \u0026#34;/tmp/node_exporter/node_exporter-$version.$arch/node_exporter\u0026#34; \u0026#34;$bin_dir\u0026#34; chown root:staff \u0026#34;$bin_dir/node_exporter\u0026#34; sudo cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/systemd/system/node_exporter.service [Unit] Description=Node Exporter After=network.target [Service] Type=simple ExecStart=/usr/local/bin/node_exporter [Install] WantedBy=multi-user.target EOF systemctl enable node_exporter.service systemctl start node_exporter.service echo \u0026#34;SUCCESS! Installation succeeded!\u0026#34; 成功安裝後 即可在http://:9100/metrics上看到metrics資訊 參考連結 Node Exporter Node Exporter安裝 ","permalink":"https://tonywu1995.github.io/prometheus/node-exporter/","summary":"前言 node exporter是用來監控Linux vm的一個Prometheus Client 提供: CPU 使用率、硬碟使用率\u0026hellip; metrics 步驟 安裝Node Exporter在Ubuntu20.04 #!/bin/bash version=\u0026#34;${VERSION:-1.2.2}\u0026#34; arch=\u0026#34;${ARCH:-linux-amd64}\u0026#34; bin_dir=\u0026#34;${BIN_DIR:-/usr/local/bin}\u0026#34; wget \u0026#34;https://github.com/prometheus/node_exporter/releases/download/v$version/node_exporter-$version.$arch.tar.gz\u0026#34; \\ -O /tmp/node_exporter.tar.gz mkdir -p /tmp/node_exporter cd /tmp || { echo \u0026#34;ERROR! No /tmp found..\u0026#34;; exit 1; } tar xfz /tmp/node_exporter.tar.gz -C /tmp/node_exporter || { echo \u0026#34;ERROR! Extracting the node_exporter tar\u0026#34;; exit 1; } sudo cp \u0026#34;/tmp/node_exporter/node_exporter-$version.$arch/node_exporter\u0026#34; \u0026#34;$bin_dir\u0026#34; chown root:staff \u0026#34;$bin_dir/node_exporter\u0026#34; sudo cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/systemd/system/node_exporter.service [Unit] Description=Node Exporter After=network.target [Service] Type=simple ExecStart=/usr/local/bin/node_exporter [Install] WantedBy=multi-user.","title":"Node Exporter建立"},{"content":"步驟 安裝Prometheus/Grafana 設定Prometheus設定向我們spring boot application位置 # my global config\rglobal:\rscrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.\revaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.\rscrape_configs:\r# The job name is added as a label `job=\u0026lt;job_name\u0026gt;` to any timeseries scraped from this config.\r- job_name: \u0026#39;My-Spring-Boot-Application\u0026#39;\r# Override the global default and scrape targets from this job every 5 seconds.\rscrape_interval: 15s\rstatic_configs:\r- targets: [\u0026#39;192.168.1.25:9100\u0026#39;] # My-Spring-Boot-Application IP\r我們使用docker-compose.yml方式來建立Prometheus/Grafana的監控環境docker-compose up -d version: \u0026#34;3.7\u0026#34;\rservices:\rprometheus:\rimage: prom/prometheus:v2.30.0\rrestart: always\rcontainer_name: prometheus\rvolumes:\r# config\r- ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml\r- ./prometheus/:/etc/prometheus/\r# tsdb data\r- ./prometheus/data:/prometheus\rcommand:\r- \u0026#39;--config.file=/etc/prometheus/prometheus.yml\u0026#39;\r# backup - \u0026#39;--web.enable-admin-api\u0026#39;\r# tsdb time delete\r- \u0026#39;--storage.tsdb.retention.time=10d\u0026#39;\r# tsdb locat\r- \u0026#39;--storage.tsdb.path=/prometheus\u0026#39;\r# reload config\r- \u0026#39;--web.enable-lifecycle\u0026#39;\rports:\r- \u0026#34;9090:9090\u0026#34;\rgrafana:\rimage: grafana/grafana:8.1.5\rrestart: always\rcontainer_name: grafana\renvironment:\rvolumes:\r- ./grafana/logs:/var/log/grafana\r- ./grafana/plugins:/var/lib/grafana/plugins\r- ./grafana/data:/var/lib/grafana\r- ./grafana/provisioning/:/etc/grafana/provisioning/\rports:\r- \u0026#34;3000:3000\u0026#34; 即可在prometheus:9090看到spring boot的metrics資料 參考連結 Prometheus Grafana ","permalink":"https://tonywu1995.github.io/java/spring-boot-monitor-2/","summary":"步驟 安裝Prometheus/Grafana 設定Prometheus設定向我們spring boot application位置 # my global config\rglobal:\rscrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.\revaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.\rscrape_configs:\r# The job name is added as a label `job=\u0026lt;job_name\u0026gt;` to any timeseries scraped from this config.\r- job_name: \u0026#39;My-Spring-Boot-Application\u0026#39;\r# Override the global default and scrape targets from this job every 5 seconds.","title":"Spring Boot監控(中)"},{"content":"前言 常在河邊走那裡不失鞋，當一個後端工程師，常常會遇到上線Application server突然無法壞掉的問題，因此我們需要一個監控的Server來輔助我們上線的Application，本篇將使用Prometheus監控server當作範例來做為展示 步驟 Spring boot 安裝Prometheus Client 在pom.xml上新增兩個dependency spring-boot-starter-actuator: spring boot內建的監控library micrometer-registry-prometheus: 在spring boot上提供prometheus metrics格式 \u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;io.micrometer\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;micrometer-registry-prometheus\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt; Spring boot 調整設定檔 在applcation.yml 新增下列設定 management:\rendpoint:\rhealth:\rshow-details: always\rprometheus:\renabled: true\rendpoints:\rweb:\rexposure:\rinclude: prometheus,health\rmetrics:\rtags:\rapplication: ${spring.application.name}\rhealth:\rdiskspace:\renabled: true\rdefaults:\renabled: false 設定好，啟動spring boot即可在http://:/actuator/prometheus看到metrics 參考連結 Spring boot Spring boot Actuator Micrometer Registry Prometheus ","permalink":"https://tonywu1995.github.io/java/spring-boot-monitor-1/","summary":"前言 常在河邊走那裡不失鞋，當一個後端工程師，常常會遇到上線Application server突然無法壞掉的問題，因此我們需要一個監控的Server來輔助我們上線的Application，本篇將使用Prometheus監控server當作範例來做為展示 步驟 Spring boot 安裝Prometheus Client 在pom.xml上新增兩個dependency spring-boot-starter-actuator: spring boot內建的監控library micrometer-registry-prometheus: 在spring boot上提供prometheus metrics格式 \u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;io.micrometer\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;micrometer-registry-prometheus\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt; Spring boot 調整設定檔 在applcation.yml 新增下列設定 management:\rendpoint:\rhealth:\rshow-details: always\rprometheus:\renabled: true\rendpoints:\rweb:\rexposure:\rinclude: prometheus,health\rmetrics:\rtags:\rapplication: ${spring.application.name}\rhealth:\rdiskspace:\renabled: true\rdefaults:\renabled: false 設定好，啟動spring boot即可在http://:/actuator/prometheus看到metrics 參考連結 Spring boot Spring boot Actuator Micrometer Registry Prometheus ","title":"Spring Boot監控(上)"},{"content":"介紹 在本機上開發的時候常常遇到需要https和domain name的狀況，例如:Line Bot的webhook測試，這時候使用ngrok就可以解決這個問題，ngork賦予你一個暫時domain name和https 安裝 Windows choco install ngrok Mac brew install ngrok 在本機上登入ngork(使用token認證) ngrok authtoken \u0026lt;token\u0026gt; 使用 ngrok http \u0026lt;Port\u0026gt; 參考連結 ngork ","permalink":"https://tonywu1995.github.io/devops/ngork/","summary":"介紹 在本機上開發的時候常常遇到需要https和domain name的狀況，例如:Line Bot的webhook測試，這時候使用ngrok就可以解決這個問題，ngork賦予你一個暫時domain name和https 安裝 Windows choco install ngrok Mac brew install ngrok 在本機上登入ngork(使用token認證) ngrok authtoken \u0026lt;token\u0026gt; 使用 ngrok http \u0026lt;Port\u0026gt; 參考連結 ngork ","title":"Ngork"},{"content":"介紹 在工作上不免要定期備份database的資料與還原datdabase的資料 備份步驟 連線進入mongo mongo -u \u0026lt;username\u0026gt; -p \u0026lt;password\u0026gt; 切換db use admin 磁碟同步與上鎖 db.runCommand({fsync:1,lock:1}) 確認是否上鎖 db.currentOp() 備份資料 mongodump --host \u0026lt;host-ip\u0026gt; --port 27017 --db \u0026lt;database\u0026gt; --authenticationDatabase admin --username \u0026lt;username\u0026gt; --password \u0026lt;password\u0026gt; --out \u0026lt;Path\u0026gt; 解鎖 db.fsyncUnlock() 還原步驟 還原 mongorestore --host \u0026lt;host-ip\u0026gt; --port 27017 --username \u0026lt;username\u0026gt; --password \u0026lt;password\u0026gt; --db \u0026lt;database\u0026gt; \u0026lt;backup file path\u0026gt; 參考連結 Mongo ","permalink":"https://tonywu1995.github.io/mongo/mongo_backup_restore/","summary":"介紹 在工作上不免要定期備份database的資料與還原datdabase的資料 備份步驟 連線進入mongo mongo -u \u0026lt;username\u0026gt; -p \u0026lt;password\u0026gt; 切換db use admin 磁碟同步與上鎖 db.runCommand({fsync:1,lock:1}) 確認是否上鎖 db.currentOp() 備份資料 mongodump --host \u0026lt;host-ip\u0026gt; --port 27017 --db \u0026lt;database\u0026gt; --authenticationDatabase admin --username \u0026lt;username\u0026gt; --password \u0026lt;password\u0026gt; --out \u0026lt;Path\u0026gt; 解鎖 db.fsyncUnlock() 還原步驟 還原 mongorestore --host \u0026lt;host-ip\u0026gt; --port 27017 --username \u0026lt;username\u0026gt; --password \u0026lt;password\u0026gt; --db \u0026lt;database\u0026gt; \u0026lt;backup file path\u0026gt; 參考連結 Mongo ","title":"Mongo備份與還原"},{"content":"介紹 SDKMAN是一款基於Linux/Mac的SDK管理工具，可以管理多個版本JDK，也可以安裝與JDK相容的套件 安裝SDKMAN $ curl -s \u0026#34;https://get.sdkman.io\u0026#34; | bash\r$ source \u0026#34;$HOME/.sdkman/bin/sdkman-init.sh\u0026#34;\rsdk version\r\u0026gt; sdkman 5.0.0+51 羅列Java版本 sdk list java 安裝JAVA sdk install java x.y.z-open 移除 sdk uninstall java ... 指定預設JAVA sdk default java 11 參考連結 SDKMAN ","permalink":"https://tonywu1995.github.io/devops/skdman/","summary":"介紹 SDKMAN是一款基於Linux/Mac的SDK管理工具，可以管理多個版本JDK，也可以安裝與JDK相容的套件 安裝SDKMAN $ curl -s \u0026#34;https://get.sdkman.io\u0026#34; | bash\r$ source \u0026#34;$HOME/.sdkman/bin/sdkman-init.sh\u0026#34;\rsdk version\r\u0026gt; sdkman 5.0.0+51 羅列Java版本 sdk list java 安裝JAVA sdk install java x.y.z-open 移除 sdk uninstall java ... 指定預設JAVA sdk default java 11 參考連結 SDKMAN ","title":"Sdkman"}]